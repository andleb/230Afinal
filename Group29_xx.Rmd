---
title: |
  | STAT 230A Final Project
  | Replication of Michalopoulos: The Origins of Ethnolinguistic Diversity
author: 
  - Andrej Leban, andrej_leban@berkeley.edu
  - Isaac Schmidt, ischmidt20@berkeley.edu
email: 
  - "andrej_leban@berkeley.edu"
  - "ischmidt20@berkeley.edu"
# date: "`r format(Sys.time(), '%B %d, %Y')`"
header-includes:
  - \usepackage{float, amsthm, amsmath, amssymb, bm, enumitem, latexsym, color, minipage-marginpar, caption, multirow, verbatim, xcolor, setspace, fancyhdr}
geometry: margin=1in
# linestretch: 1.5
output:
  pdf_document:
    # TODO: enable for the final writeup
    toc: no
    number_sections: true
    df_print: kable
papersize: a4
urlcolor: blue
bibliography: [references.bib]
editor_options:
  markdown:
    wrap: 120
always_allow_html: true
---

```{r setup, echo = FALSE, message=FALSE, warning=FALSE}
library(conflicted)
library(MASS)
library(sandwich)
library(lmtest)

# extra:
library(gsubfn)
library(reshape2)

library(data.table)

library(knitr)
library(kableExtra)
library(ggrastr)

library(readstata13)
library(sf)

library(viridis)
library(tidyverse)

# NOTE: this is to make only the displayed code smaller
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr") 

# set default knitr chunks
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.height = 4,
  fig.pos = "H",
  fig.width = 6,
  message = FALSE,
  warning = FALSE,
  cache = F,
  results = 'hide', 
  size="small"
)

options(knitr.kable.NA = '')

# define my_theme - append here
my_theme <- theme_minimal()
```

`r #TODO: margins, font size, group name & name in upper right`

<!-- LaTeX preamble -->
  \newcommand{\E}{{\mathbb E}}
\newcommand{\se}{{\mathcal{E}}}
\newcommand{\R}{{\mathbb R}}
\renewcommand{\P}{{\mathbb P}}
\newcommand{\ac}{{\mathcal{A}}}
\newcommand{\A}{{\mathcal{A}}}
\newcommand{\B}{{\mathcal{B}}}
\newcommand{\T}{{\mathcal{T}}}
\newcommand{\Z}{{\mathcal{Z}}}
\newcommand{\K}{{\mathcal{K}}}
\newcommand{\lc}{{\mathcal{L}}}
\newcommand{\Ps}{{\mathcal{P}}}
\newcommand{\pa}{{\mathring{p}}}
\newcommand{\F}{{\cal F}}
\newcommand{\samp}{{\mathcal{X}}}
\newcommand{\X}{{\mathcal{X}}}
\newcommand{\hi}{{\hat{\Phi}}}

\def\qt#1{\qquad\text{#1}}

\def\argmin{\mathop{\rm argmin}}
\def\argmax{\mathop{\rm argmax}}

\setlength{\parskip}{1.4 \medskipamount}

\onehalfspacing

\pagestyle{fancy}
\fancypagestyle{plain}{\pagestyle{fancy}}
\fancyhead[R]{Group 29, Isaac Schmidt}



```{r dataImport1, echo=F}
cells = read_sf(dsn = 'data_raw/Virtual_country', layer = 'virtual_cntrygrid')
countries = read_sf(dsn = 'countries', layer = 'countries')
data = read.dta13("data_raw/Tables1-3a.dta")
```

```{r rename1, echo=F}
colnames(data) = c('countryCode', 'entryYear', 'countryName', 'avgTemp', 
                   'avgPrecip', 'seaDist', 'avgElev', 'sdElev', 'absLat', 
                   'dispElev', 'numLang', 'suitableCells', 'dispSuitable',
                   'climate', 'soil', 'sdClimate', 'sdSoil', 'sdSuitable', 
                   'avgSuitable', 'pop95', 'area', 'lnLang', 'africa', 
                   'europe', 'americas', 'lnPopDens1995', 'migrationDist', 
                   'lnArea', 'pctIndigenous', 'lnPopDens1500', 
                   'agriTran', 'asiaPac')
```

# Paper Summary & Summary Statistics Table

## Paper Summary

The paper by Michalopoulos [@michalopoulos_origins_2012] aims to explain ethnolinguistic diversity within and across countries by assuming that a proxy quantity—the number of languages per square kilometer—is determined by a selection of various economic, historical, andgeographic variables. It determines that *variation in regional land quality* and *variation in elevation* are the most significant determinants of linguistic diversity. The hypothesis underpinning this examination is that differences in local land characteristics induce different levels of human capital across locations, which in turn, gives rise to localized ethnicities that are characterized by separate languages. The results of the empirical study presented are found to be consistent with this hypothesis.

The empirical results are obtained separately by three regressions:  

* **Cross-country**: this takes the current political borders as the unit within which covariates such as the number of languages are counted.

* **Virtual countries**: To account for the arbitrary nature of some political boundaries with respect to ethnolinguistic groupings, the world is split into arbitrary *virtual countries* and the regression is performed again.
  
* **Adjacent regions**: To account for a potentially high "baseline" effect in some regions, adjacent regions are compared directly, which neutralizes region-specific fixed effects and focuses on the effect of the variables under consideration.
  
<!-- Finally, in regions that have undergone a major demographic shift in the last 500 years, the explanatory power of the model -->
<!-- is found to be significantly weaker; these regions are controlled for with a dummy variable. -->

## Exploratory Data Analysis and Summary Table

The data comes from multiple sources: the standard geographic data was sourced from the *Geographically Based Economic Data database*, the data on land quality for agriculture comes from *Ramankutty et al. (2002)*, and the data on the distribution of languages comes from the *World Language Mapping System*. Fortunately, the data provided by the author was already processed and cleaned to the extent used in the paper, so all we did was rename columns to more descriptive names.

The paper lacks a true summary table and shows a couple of EDA figures instead. We replicate two of those figures, and then display our own summary table of the features used in the paper's first regression—the *cross-country model*. Figure \ref{fig:suit} shows the distribution of land suitability for agriculture across the world at a resolution of .5-by.5 decimal degrees. The dependent variable represents the probability that a particular grid cell may be cultivated. 

```{r fig1, fig.cap="\\label{fig:suit} Land quality for agriculture across countries", echo=F, cache=T, fig.width = 6, fig.height=4}
fig1 = ggplot(cells) + rasterize(geom_sf(aes(fill = suit_new), colour = NA), dpi=450) +
  scale_fill_viridis_c("Land quality", direction = -1 ) + my_theme
fig1
```

```{r greeceNepal, cache=TRUE, echo=F}
greeceCells = countries %>% filter(COUNTRY == 'Greece') %>%
  st_intersection(y = cells)
nepalCells = countries %>% filter(COUNTRY == 'Nepal') %>%
  st_intersection(y = cells)
```

Figure \ref{fig:kde1} shows the distribution of land quality within two countries selected in the paper—Greece and Nepal, obtained with a kernel density estimate using the Epanechnikov kernel.

```{r worldMap, fig.cap="\\label{fig:kde1} Kernel density of land quality in Greece and Nepal", echo=F, fig.width = 5, fig.height=3}
plot(
  density(greeceCells$suit_new, kernel = "epanechnikov"),
  xlim = c(0, 1),
  xlab = 'Land quality per region',
  ylab = 'Density',
  main = '',
  lty = 2
)
lines(density(nepalCells$suit_new, kernel = "epanechnikov"), col = 'red')
legend(
  .1,
  3,
  legend = c(
    'Distribution of land quality in Greece',
    'Distribution of land quality in Nepal'
  ),
  col = c("black", "red"),
  lty = 2:1,
  cex = .75
)
```

Table \ref{tab:summaryPrint} shows summary statistics of important variables for the first model. The dependent variable is `numLang`, which is the number of languages whose "traditional homeland" intersects with the country's boundary. Additional covariates are measures of centrality and variablity of the geographic data, the log of the country's 1995 population, human migration distance from Africa, and distance from a large body of water. While some other variables in the provided dataset have missing values for some countries, note that all variables included in the first regression are known for all countries.  

```{r summary, results='hide', echo=F}
count = function(x) {
  (sum( ~ is.na(x)))
}

sumTable <- data %>% select(
  c(
    'numLang',
    'sdElev',
    'sdSuitable',
    'avgElev',
    'avgSuitable',
    'absLat',
    'avgPrecip',
    'avgTemp',
    'lnArea',
    'seaDist',
    'migrationDist',
    'lnPopDens1995'
  )
) %>%
  summarise_each(
    funs(
      min = min,
      median = median,
      max = max,
      mean = mean,
      iqr = quantile(., 0.75) - quantile(., 0.25),
      sd = sd,
      n = sum(!is.na(.))
    )
  ) %>%
  gather(var, val) %>%
  separate(var, into = c("var", "stat"), sep = "_") %>%
  spread(var, val) %>% column_to_rownames(var = "stat") %>%
  select(
    c(
      'numLang',
      'sdElev',
      'sdSuitable',
      'avgElev',
      'avgSuitable',
      'absLat',
      'avgPrecip',
      'avgTemp',
      'lnArea',
      'seaDist',
      'migrationDist',
      'lnPopDens1995'
    )
  ) %>%
  mutate_if(is.numeric, ~ round(., 2)) %>% slice(5, 4, 2, 3, 7)
```

```{r summaryPrint, results='show', echo=F}
knitr::kable(sumTable, toprule = '', bottomrule = '', booktabs = TRUE, linesep = c(""), caption = 'Summary statistics for covariates in cross-country analysis') %>% row_spec(0, angle = 90)
```


# Analysis 1: Cross-Country

The first model regresses the (log) number of languages within each country on the features described above. Michalopolous presents five different regression models, each containing a different number of covariates. The model, as described in the original paper, is the following:

$$
\ln\left(\text{numLang}_i\right) = \beta_0 + \beta_1*\text{absLat}_i + \beta_2*\text{sdElev}_i + \beta_3*\text{sdSuitable}_i + \beta_4* X_i + \epsilon_i
$$
The first model only includes absolute latitude, the second model adds the mean and standard deviation of both elevation and land quality within each country, and the remaining models add additional covariates $X_i$.

## Replication

As the code and the data files were provided completely by the author, we were able to replicate the results perfectly. Table \ref{tab:tbl1Print} perfectly replicates Table 1 in the original paper, and Table \ref{tab:tbl1Info} displays additional information about each model. Note that all variables, including indicators, were standardized by Michalopolous, so we did so here as well. Unsurprisingly, given the increasing number of features, the observed $R^2$ also increases with each model. In all four models, variation in elevation, and variation in land quality were useful predictors of the log number of languages, as originally hypothesized by the author. Mean precipitation, log of area, and migratory distance from Ethiopia were also significant predictors whenever they were included.

```{r standardize1, echo=F}
standardize = function(vec) {return ((vec - mean(vec, na.rm = TRUE)) / sd(vec, na.rm = TRUE))}
 
modelCols = c('entryYear', 'avgTemp', 'avgPrecip', 'seaDist', 'avgElev',
             'sdElev', 'absLat', 'numLang', 'dispSuitable', 'climate',
             'soil', 'sdClimate', 'sdSoil', 'sdSuitable', 'avgSuitable',
             'pop95', 'area', 'lnLang', 'lnPopDens1995', 'migrationDist',
             'lnArea', 'pctIndigenous', 'lnPopDens1500', 'agriTran',
             'americas', 'europe', 'africa', 'asiaPac')
# for (col in modelCols) {
#  data[,col] = standardize(data[,col])
# }
# NOTE: Easier to say what we're not standardizing; also for the robustness checks we need to keep a non-standardized copy
dataStd = data %>% mutate(across(!countryName & !countryCode , standardize))
```

```{r model1.1, echo=F}
model1.1 = lm(lnLang ~ absLat, dataStd)
```

```{r model1.2, echo=F}
model1.2 = lm(lnLang ~ sdElev + sdSuitable + avgElev + avgSuitable + absLat, dataStd)
```

```{r model1.3, echo=F}
model1.3 = lm(lnLang ~ sdElev + sdSuitable + avgElev + avgSuitable + absLat
            + avgPrecip + avgTemp + lnArea + seaDist + migrationDist, dataStd)
```

```{r model1.4, echo=F}
model1.4 = lm(lnLang ~ sdElev + sdSuitable + avgElev + avgSuitable + absLat
            + avgPrecip + avgTemp + lnArea + seaDist + migrationDist + lnPopDens1995
            + africa + europe + americas + asiaPac, dataStd)
```

```{r model1.5, echo=F}
missingData = is.na(dataStd$agriTran) | is.na(dataStd$entryYear) | is.na(dataStd$lnPopDens1500)
for (col in modelCols) {
  dataStd[!missingData, col] = standardize(dataStd[!missingData,col])
}

model1.5 = lm(lnLang ~ sdElev + sdSuitable + avgElev + avgSuitable + absLat
            + avgPrecip + avgTemp + lnArea + seaDist + migrationDist + lnPopDens1995
            + lnPopDens1500 + entryYear + agriTran
            + africa + europe + americas + asiaPac, dataStd, na.action = na.exclude)
```

```{r tbl1, results='hide', echo=F}
models = paste0("model1.", 1:5)
coefs = sapply(models, function(model) {coeftest(get(model), vcov = vcovHC(get(model), "HC1"))[, 1]}) %>% 
  unlist() %>% data.frame()
coefs$model = substr(row.names(coefs), 1, 8)
coefs$column = substr(row.names(coefs), 10, nchar(row.names(coefs)))

ses = sapply(models, function(model) {coeftest(get(model), vcov = vcovHC(get(model), "HC1"))[, 2]}) %>% 
  unlist() %>% data.frame()
ses$model = substr(row.names(ses), 1, 8)
ses$column = substr(row.names(ses), 10, nchar(row.names(ses)))

pvals = sapply(models, function(model) {coeftest(get(model), vcov = vcovHC(get(model), "HC1"))[, 4]}) %>% 
  unlist() %>% data.frame()
pvals$model = substr(row.names(pvals), 1, 8)
pvals$column = substr(row.names(pvals), 10, nchar(row.names(pvals)))

order = c('sdElev', 'sdSuitable', 'avgElev', 'avgSuitable', 'absLat', 
          'avgPrecip', 'avgTemp', 'lnArea', 'seaDist', 'migrationDist',
          'lnPopDens1995', 'lnPopDens1500', 'entryYear', 'agriTran')
tbl1 = coefs %>% pivot_wider(names_from = "model", values_from = '.') %>% 
  merge(ses %>% pivot_wider(names_from = "model", values_from = '.'),
        by = 'column',
        suffixes = c('Estimate', 'SE')
  ) %>% 
  merge(pvals %>% pivot_wider(names_from = "model", values_from = '.'),
        by = 'column') %>%
  slice(match(order, column)) %>% 
  column_to_rownames(var = "column") 
```

```{r tbl1Print, results='show', echo=F}
tbl1format = data.frame(tbl1)
for (model in models) {
  estimCol = paste0(model, 'Estimate')
  seCol = paste0(model, 'SE')
  notNA = !is.na(tbl1[, estimCol])
  
  tbl1format[notNA, estimCol] = as.character(formatC(tbl1format[notNA, estimCol], digits = 3, format = 'f'))
  tbl1format[notNA, seCol] = as.character(formatC(tbl1format[notNA, seCol], digits = 3, format = 'f'))
  significant = tbl1[notNA, model] <= .01
  
  tbl1format[notNA, estimCol] = cell_spec(tbl1format[notNA, estimCol], italic = significant)
  tbl1format[notNA, seCol] = cell_spec(tbl1format[notNA, seCol], italic = significant)
}

rownames(tbl1format) = c('Variation in elevation', 'Variation in land quality',
                           'Mean elevation', 'Mean land quality',
                           'Absolute latitude', 'Mean precipitation',
                           'Mean temperature', 'Ln(Area)',
                           'Distance from the sea', 'Migratory dist. from Ethiopia',
                           'Ln(Population density in 1995)', 'Ln(Population density in 1500)',
                           'Year of independence', 'Time of agricultural transition')

order = c(1, 6, 2, 7, 3, 8, 4, 9, 5, 10)
col.names = c(paste0("(", 1:5, ") Coef."), paste0("(", 1:5, ") S.E."))[order]

tbl1format %>% select(order) %>%
  knitr::kable(toprule = '', bottomrule = '', booktabs = TRUE, linesep = c(""),
             col.names = col.names, align = "r", row.names = T, 
             caption = 'Main specification for the cross-country analysis. Italics indicate significance at the 99\\% level.', escape = F) %>% row_spec(0, angle = 90) %>% kable_styling(font_size = 8)
```

```{r tbl1Info, results='show', echo=F}
tbl1info = data.frame(
  model = 1:5,
  cont = c("No", "No", "No", "No", "Yes"),
  nobs = sapply(models, function(model) { nobs(get(model))}),
  rsq = sapply(models, function(model) {
    formatC(summary(get(model))$r.squared, digits = 2, format = 'f')
    }), row.names = NULL
  )
tbl1info %>% 
  knitr::kable(toprule = '', bottomrule = '', booktabs = TRUE,
               col.names = c('Model', 'Continental Indicators', 'Observations', 'R-Squared'),
               caption = "Information for each model in cross-country analysis.")
```


### Critique of Assumptions

## Robustness Check 

### Table 2A

```{r model1.1Rob, results='hide', echo=F, eval=T}
robust1.1 <- glm.nb(numLang ~ absLat + sdSuitable + sdElev + avgElev + avgSuitable + avgPrecip + avgTemp + lnArea 
                    + seaDist + migrationDist + lnPopDens1995 + lnPopDens1500 + entryYear + agriTran + 
                      africa + europe + americas + asiaPac
                    , data, na.action = na.exclude)
```

```{r model1.1RobTable, results='show', echo=F, eval=T}
summary(robust1.1)
```
NOTE: Matches!


```{r model1.2Rob, results='hide', echo=F, eval=T}
robust1.2 <- lm(lnLang ~ absLat + dispElev + dispSuitable + avgElev + avgSuitable + avgPrecip +  avgTemp +  
                lnArea +  seaDist + migrationDist +  lnPopDens1995 + lnPopDens1500 + entryYear + agriTran + 
                africa + europe + americas + asiaPac,
                data, na.action = na.exclude)
                    
```

```{r model1.2RobTable, results='show', echo=F, eval=T}
summary(robust1.2)
```
NOTE: matches or exceeds in significance, as well

```{r model1.3Rob, results='hide', echo=F, eval=T}
robust1.3 <- lm(lnLang ~ absLat + sdElev + sdClimate + avgElev + climate + avgPrecip +  avgTemp +  
                lnArea +  seaDist + migrationDist +  lnPopDens1995 +  lnPopDens1500 + entryYear + agriTran + 
                africa + europe + americas + asiaPac,
                data, na.action = na.exclude)
                    
```

```{r model1.3RobTable, results='show', echo=F, eval=T}
summary(robust1.3)
```

NOTE: matches!


```{r model1.4Rob, results='hide', echo=F, eval=T}
# NOTE: the conditional doesn't remove anything from the `data` df
data1.4 <- data[(data$suitableCells > 9) & (data$lnArea > -10), ]

robust1.4 <- lm(lnLang ~ absLat + sdElev + sdSoil + avgElev + soil + avgPrecip +  avgTemp +  
                lnArea +  seaDist + migrationDist +  lnPopDens1995 +  lnPopDens1500 + entryYear + agriTran + 
                africa + europe + americas + asiaPac,
                data1.4, na.action = na.exclude)
                    
```

```{r model1.4RobTable, results='show', echo=F, eval=T}
summary(robust1.4)
```
NOTE: matches!


### Table 2B

```{r data_import2b, echo=F, eval=T}
data2b <- read.dta13("data_raw/Table_3b.dta")

standardized <- list("lpd1500", "yrentry", "agritran", "elf", "elf3", "elf5", "elf7", "elf9",
                     "abs_lat", "sd_climsuit", "sd_emean", "emean", "mean_climsuit", "precav",
                     "tempav", "lnareakm2", "distc", "migdist", "lnpop95", "americas", "reg_eap",
                     "africa", "europe", "nmbr_climsuit")

notStdized <- names(data2b)[! names(data2b) %in%  standardized]
data2bStd <- data2b %>% mutate(across(! all_of(notStdized) , standardize))

```

`TODO: write up a bit about the datasets used here`


```{r model1.2.1, results='hide', echo=F, eval=T}
robust1.2.1 <- lm(elf ~ abs_lat, data2bStd, na.action = na.exclude)

```

```{r model1.2.1Table, results='show', echo=F, eval=T}
summary(robust1.2.1)
```

OK

```{r model1.2.2, results='hide', echo=F, eval=T}
robust1.2.2 <- lm(elf ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit,
                  data2bStd, na.action = na.exclude)

```

```{r model1.2.2Table, results='show', echo=F, eval=T}
summary(robust1.2.2)
```
OK


```{r model1.2.3, results='hide', echo=F, eval=T}
robust1.2.3 <- lm(elf ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit + 
                  precav + tempav + lnareakm2 + distc + migdist + lnpop95 + lpd1500 + yrentry + agritran + 
                  africa + europe + americas + reg_eap
                  , data2bStd, na.action = na.exclude)

```

```{r model1.2.3Table, results='show', echo=F, eval=T}
summary(robust1.2.3)
```
OK

```{r model1.2.4, results='hide', echo=F, eval=T}
robust1.2.4 <- lm(elf3 ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit + 
                  precav + tempav + lnareakm2 + distc + migdist + lnpop95 + lpd1500 + yrentry + agritran + 
                  africa + europe + americas + reg_eap
                  , data2bStd, na.action = na.exclude)

```

```{r model1.2.4Table, results='show', echo=F, eval=T}
summary(robust1.2.4)
```

OK

```{r model1.2.5, results='hide', echo=F, eval=T}
robust1.2.5 <- lm(elf5 ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit + 
                  precav + tempav + lnareakm2 + distc + migdist + lnpop95 + lpd1500 + yrentry + agritran + 
                  africa + europe + americas + reg_eap
                  , data2bStd, na.action = na.exclude)

```

```{r model1.2.5Table, results='show', echo=F, eval=T}
summary(robust1.2.5)
```

OK


```{r model1.2.6, results='hide', echo=F, eval=T}
robust1.2.6 <- lm(elf7 ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit + 
                  precav + tempav + lnareakm2 + distc + migdist + lnpop95 + lpd1500 + yrentry + agritran + 
                  africa + europe + americas + reg_eap
                  , data2bStd, na.action = na.exclude)

```

```{r model1.2.6Table, results='show', echo=F, eval=T}
summary(robust1.2.6)
```

OK


```{r model1.2.7, results='hide', echo=F, eval=T}
robust1.2.7 <- lm(elf9 ~ abs_lat + sd_emean + sd_climsuit + emean + mean_climsuit + 
                  precav + tempav + lnareakm2 + distc + migdist + lnpop95 + lpd1500 + yrentry + agritran + 
                  africa + europe + americas + reg_eap
                  , data2bStd, na.action = na.exclude)

```

```{r model1.2.Table, results='show', echo=F, eval=T}
summary(robust1.2.7)
```

OK

# Analysis 2: Virtual Country (Re-Analysis)

The second analysis Michalopolous presents in his paper is essentially a repeat of the the previous, but aggregating over "virtual" countries instead of real ones, "in order to investigate whether the relationship between geography and ethnic diversity holds true at an arbitrary level of aggregation."

As with the previous analysis, the geographic features are derived from a dataset of cells, each of size .5-by.5 decimal degrees. However, instead of aggregating these cells at the country level as before, we now split up the world into blocks of size 2.5-by-2.5 decimal degrees, with each block containing 25 cells. Each block thus becomes a "virtual country."

To obtain the number of languages in each virtual country, Michalopolous simply intersected the shapefile provided in the World Language Mapping System with the grid of countries. However, probably due to the proprietary nature of the WLMS, the "number of languages" variable was withheld from the public data download, meaning we could not exactly replicate the analysis.

Fortunately, we stumbled across the *Geo-referencing of Ethnic Groups* (GREG) [@weidmann_representing_2010] dataset, which contains a shapefile of the locations of ethnic groups across the world. As Michalopolous was only using linguistic diversity as a proxy for ethnic diversity, we decided it would be useful to try to see if the original paper's results held up with the GREG data.

The original GREG dataset required some manipulation to get it in a format suitable to swap in for the WLMS. For details, see the appendix, which shows the geoprocessing steps performed with the `geopandas` module in Python.

In the original paper, Michalopolous described the steps he took to filter the virtual countries, on criteria mostly based on the amount of "coverage" each country had in the WLMS data. In other words, if a large portion of a virtual country was in an area which contained no languages—for example, the Sahara Desert—that virtual country was excluded from the analysis. The data download, which contained the virtual countries after the filter had been applied, contained 1,888 virtual countries. Due to differences in coverage between WLMS and GREG, applying the same criteria to GREG would have resulted in 2,476 countries. Including these additional countries would have required obtaining the other features for these areas, and as Michalopolous did not document this procedure well, we decided that this was not feasible. The end result was that we looked at the intersection of WLMS and GREG, which excluded the ~600 countries from the dataset derived from GREG, but also about 30 countries that had enough coverage in WLMS, but did not in GREG.

Finally, the actual regressions performed in the paper used a dataset that was further filtered down. That is, there must have been at least 3000 people living in the virtual country in 1995, and at least 10 of the 25 cells that comprise a virtual country had to have been completely covered by the WLMS dataset. We applied both of these criteria here as well when reproducing the regressions.

```{r dataImport2, echo=F}
data2 = read.dta13('data_raw/Tables4-7b.dta')
greg = read.csv('greg.csv')
colnames(greg) = c('uniq_cnt25', 'number_suit_valid25', 'nmbrlang')

data2 = data2 %>% select(-c('nmbrlang', 'number_suit_valid25')) %>% merge(greg, by = 'uniq_cnt25')

data2$lnnmbrlang = log(data2$nmbrlang)
```

```{r rename2, echo=F}
colnames(data2) = c('virtCode', 'countryCode', 'climate', 'soil',
                   'sdClimate', 'sdSoil', 'seaDist', 'avgElev', 'avgPrecip',
                   'avgTemp', 'sdElev', 'waterArea', 'avgSuitable',
                   'sdSuitable', 'popDens95', 'range', 'area', 'withinCountry', 
                   'numCountry', 'migrationDist', 'lnLang', 'totalPop95',
                   'absLat', 'tropics', 'erange_gecon', 'lnArea', 
                   'lnPopDens95', 'pctIndigenous', 'diffAvgElev',
                   'diffAvgPrecip', 'diffAvgTemp', 'diffAvgSuit',
                   'overlap', 'suitableCells', 'numLang')

modelCols = c('lnLang', 'sdElev', 'sdSuitable', 'avgElev', 'avgSuitable',
              'absLat', 'avgPrecip', 'avgTemp', 'lnArea', 'seaDist', 'waterArea',
              'withinCountry', 'numCountry', 'migrationDist', 'lnPopDens95')
```

## Replication

The model specification for this analysis is almost exactly the same as before, except now each unit $i$ is a virtual country, and "numLang" is really the number of unique ethnic groups:

$$
\ln\left(\text{numLang}_i\right) = \beta_0 + \beta_1*\text{absLat}_i + \beta_2*\text{sdElev}_i + \beta_3*\text{sdSuitable}_i + \beta_4* X_i + \epsilon_i
$$
Additionally, regressions 2.5, 2.6, and 2.7 are performed only on virtual countries meeting a certain criterion. Regression 2.5 looks only at virtual countries located in the tropics, 2.6 looks at countries not located in the tropics, and 2.7 filters to virtual countries that are located entirely within a real country.

```{r model2.1, echo=F}
condition = (data2$totalPop95 >= 3000) & (data2$suitableCells >= 10)
for (col in modelCols) {
  data2[condition, paste0(col, '1')] = standardize(data2[condition, col])
}
model2.1 = lm(lnLang1 ~ absLat1, data2 %>% filter(condition))
coefs = coeftest(model2.1, vcov = vcovCL, cluster = ~countryCode)[, 1]
ses = coeftest(model2.1, vcov = vcovCL, cluster = ~countryCode)[, 2]
pvals = coeftest(model2.1, vcov = vcovCL, cluster = ~countryCode)[, 4]
```

```{r model2.1table, echo=F, results='show'}
coeftest(model2.1, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.2, echo=F}
model2.2 = lm(lnLang1 ~ sdElev1 + sdSuitable1 + avgElev1 + avgSuitable1 + absLat1,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.2, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.2, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.2, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.2table, echo=F, results='show'}
coeftest(model2.2, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.3, echo=F}
model2.3 = lm(lnLang1 ~ sdElev1 + sdSuitable1 + avgElev1 + avgSuitable1 + absLat1
            + avgPrecip1 + avgTemp1 + lnArea1 + seaDist1 + waterArea1
            + withinCountry1 + numCountry1 + migrationDist1,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.3, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.3, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.3, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.3table, echo=F, results='show'}
coeftest(model2.3, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.4, echo=F}
model2.4 = lm(lnLang1 ~ sdElev1 + sdSuitable1 + avgElev1 + avgSuitable1 + absLat1
            + avgPrecip1 + avgTemp1 + lnArea1 + seaDist1 + waterArea1
            + withinCountry1 + numCountry1 + migrationDist1 + lnPopDens951,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.4, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.4, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.4, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.4table, echo=F, results='show'}
coeftest(model2.4, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.5, echo=F}
condition = (data2$totalPop95 >= 3000) & (data2$suitableCells >= 10) & (data2$tropics == 1)
for (col in modelCols) {
  data2[condition, paste0(col, '5')] = standardize(data2[condition, col])
}
model2.5 = lm(lnLang5 ~ sdElev5 + sdSuitable5 + avgElev5 + avgSuitable5 + absLat5
            + avgPrecip5 + avgTemp5 + lnArea5 + seaDist5 + waterArea5
            + withinCountry5 + numCountry5 + migrationDist5 + lnPopDens955,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.5, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.5, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.5, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.5table, echo=F, results='show'}
coeftest(model2.5, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.6, echo=F}
condition = (data2$totalPop95 >= 3000) & (data2$suitableCells >= 10) & (data2$tropics == 0)
for (col in modelCols) {
  data2[condition, paste0(col, '6')] = standardize(data2[condition, col])
}
model2.6 = lm(lnLang6 ~ sdElev6 + sdSuitable6 + avgElev6 + avgSuitable6 + absLat6
            + avgPrecip6 + avgTemp6 + lnArea6 + seaDist6 + waterArea6
            + withinCountry6 + numCountry6 + migrationDist6 + lnPopDens956,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.6, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.6, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.6, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.6table, echo=F, results='show'}
coeftest(model2.6, vcov = vcovCL, cluster = ~countryCode)
```

```{r model2.7, echo=F}
condition = (data2$totalPop95 >= 3000) & (data2$suitableCells >= 10) & (data2$withinCountry == 1)
for (col in modelCols) {
  data2[condition, paste0(col, '7')] = standardize(data2[condition, col])
}
model2.7 = lm(lnLang7 ~ sdElev7 + sdSuitable7 + avgElev7 + avgSuitable7 + absLat7
            + avgPrecip7 + avgTemp7 + lnArea7 + seaDist7 + waterArea7
            + migrationDist7 + lnPopDens957,
            data2 %>% filter(condition))
coefs = c(coefs, coeftest(model2.7, vcov = vcovCL, cluster = ~countryCode)[, 1])
ses = c(ses, coeftest(model2.7, vcov = vcovCL, cluster = ~countryCode)[, 2])
pvals = c(pvals, coeftest(model2.7, vcov = vcovCL, cluster = ~countryCode)[, 4])
```

```{r model2.7table, echo=F, results='show'}
coeftest(model2.7, vcov = vcovCL, cluster = ~countryCode)
```

```{r tbl4, results='hide', echo=F}
models = paste0("model2.", 1:7)
coefs = data.frame(coefs, row.names = paste0("model2.", cumsum(names(coefs) == "(Intercept)"), ".", names(coefs)))
coefs$model = substr(row.names(coefs), 1, 8)
coefs$column = substr(row.names(coefs), 10, nchar(row.names(coefs)) - 1)

ses = data.frame(ses, row.names = paste0("model2.", cumsum(names(ses) == "(Intercept)"), ".", names(ses)))
ses$model = substr(row.names(ses), 1, 8)
ses$column = substr(row.names(ses), 10, nchar(row.names(ses)) - 1)

pvals = data.frame(pvals, row.names = paste0("model2.", cumsum(names(pvals) == "(Intercept)"), ".", names(pvals)))
pvals$model = substr(row.names(pvals), 1, 8)
pvals$column = substr(row.names(pvals), 10, nchar(row.names(pvals)) - 1)

order = c('sdElev', 'sdSuitable', 'avgElev', 'avgSuitable', 'absLat',
          'avgPrecip', 'avgTemp', 'lnArea', 'seaDist', 'waterArea',
          'withinCountry', 'numCountry', 'migrationDist', 'lnPopDens95')

pvalsPivoted = pvals %>% pivot_wider(names_from = "model", values_from = 'pvals') %>% slice(match(order, column))
# tbl4 = coefs %>% pivot_wider(names_from = "model", values_from = 'coefs') %>%
#   merge(ses %>% pivot_wider(names_from = "model", values_from = 'ses'),
#         by = 'column',
#         suffixes = c('Estimate', 'SE')
#   ) %>%
#   merge(pvals %>% pivot_wider(names_from = "model", values_from = 'pvals'),
#         by = 'column') %>%
#   slice(match(order, column)) %>%
#   column_to_rownames(var = "column")
# tbl4

tbl4 = rbind(coefs %>% pivot_wider(names_from = "model", values_from = 'coefs'), ses %>% pivot_wider(names_from = "model", values_from = 'ses'))
tbl4$stat = c(rep('Estimate', 15), rep('SE', 15))
indices = c(rbind(match(order, tbl4$column), match(order, tbl4$column) + 15))
tbl4 = tbl4 %>% slice(indices)

```

```{r tbl4Print, results='show', echo=F}
tbl4format = data.frame(tbl4)
for (model in models) {
  estimRows = !is.na(tbl4[, model]) & (tbl4$stat == 'Estimate')
  seRows = !is.na(tbl4[, model]) & (tbl4$stat == 'SE')

  tbl4format[estimRows, model] = sprintf(fmt = "%.3f", tbl4[estimRows, model] %>% unlist() %>% as.numeric())
  tbl4format[seRows, model] = paste0("(", sprintf(fmt = "%.3f", tbl4[seRows, model] %>% unlist() %>% as.numeric()), ")")
  
  significant = rep(pvalsPivoted[, model] < .01, each = 2)
  significant[is.na(significant)] = FALSE
  tbl4format[estimRows, model] = cell_spec(tbl4format[estimRows, model], italic = significant[estimRows])
  tbl4format[seRows, model] = cell_spec(tbl4format[seRows, model], italic = significant[seRows])
}

tbl4format$name = c('Variation in elevation', NA, 'Variation in land quality', NA,
                           'Mean elevation', NA, 'Mean land quality', NA,
                           'Absolute latitude', NA, 'Mean precipitation', NA,
                           'Mean temperature', NA, 'Ln(Area)', NA,
                           'Distance from the sea', NA, 'Water area', NA,
                         'Within-country indicator', NA, 'Number of countries', NA,
                         'Migratory dist. from Ethiopia', NA, 'Ln(Population density in 1995)', NA)

col.names = c("Variable", paste0("(", 1:7, ")"))

tbl4format %>% select(10, 2:8) %>%
  knitr::kable(toprule = '', bottomrule = '', booktabs = TRUE, linesep = c("", "\\addlinespace"),
             col.names = col.names, align = "r", row.names = F,
             caption = 'Main specification for the virtual analysis. Italics indicate significance at the 99\\% level.', escape = F)# %>% row_spec(0, angle = 90) %>% kable_styling(font_size = 8)

```


## Robustness Check

<!-- # "Re-analysis" -->


# References

<div id="refs"></div>


\newpage
# Appendix: code
<!-- NOTE: add code chunks to be displayed here -->
```{r codeAppendix, ref.label=c('dataImport1', 'rename1', 'greeceNepal', 'worldMap', 'summary', 'standardize1', 'model1.1', 'model1.2', 'model1.3', 'model1.4', 'model1.5', 'tbl1', 'tbl1Print', 'tbl1Info', 'model1.1Rob', 'model1.2Rob', 'model1.3Rob', 'model1.4Rob', 'data_import2b', 'model1.2.1', 'model1.2.2', 'model1.2.3', 'model1.2.4', 'model1.2.5', 'model1.2.6', 'model1.2.7', 'dataImport2', 'rename2', 'model2.1', 'model2.1table', 'model2.2', 'model2.2table', 'model2.3', 'model2.3table', 'model2.4', 'model2.4table', 'model2.5', 'model2.5table', 'model2.6', 'model2.6 table', 'model2.7', 'model2.7table', 'tbl4', 'tbl4Print', 'tbl4Info'), echo=T, eval=F}

```








